{
  "active": false,
  "connections": {
    "Receive Person Inputs - Subflow Trigger": {
      "main": [
        [
          {
            "node": "Workflow Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Configure Chat Model - Util OpenRouter": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Connection Message - Util OpenRouter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Get LinkedIn Profile Details - HTTP Apify": {
      "main": [
        [
          {
            "node": "Check Previous Jobs",
            "type": "main",
            "index": 0
          },
          {
            "node": "If Profile Data Present - IF",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Apify Error 402 - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Connection Message - Util OpenRouter": {
      "main": [
        [
          {
            "node": "If Connection Message Present - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Configure Fallback Chat Model - Util OpenRouter": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Connection Message - Util OpenRouter",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "If Connection Message Present - IF": {
      "main": [
        [
          {
            "node": "Update People Connection Message - AT People",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Attempts lt 2 - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Attempts lt 2 - IF": {
      "main": [
        [
          {
            "node": "Generate Connection Message - Util OpenRouter",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Fail Workflow - Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Profile Data Present - IF": {
      "main": [
        [
          {
            "node": "Generate Connection Message - Util OpenRouter",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "No Operation - Util",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify - Get limits": {
      "main": [
        [
          {
            "node": "Check Apify Capacity - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Apify Capacity - IF": {
      "main": [
        [
          {
            "node": "Get LinkedIn Profile Details - HTTP Apify",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify Actors Config - Set": {
      "main": [
        [
          {
            "node": "Apify - Get limits",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Apify Actors Config - Set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify Error 402 - IF": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Workflow Data": {
      "main": [
        [
          {
            "node": "Apify Actors Config - Set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Model - OpenRouter": {
      "ai_languageModel": [
        [
          {
            "node": "Summarize Previous Jobs - LLM",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "If Summary Text Present - IF": {
      "main": [
        [
          {
            "node": "Update Previous Job Summary - AT People",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Retry Count LT 2 - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Retry Count LT 2 - IF": {
      "main": [
        [
          {
            "node": "Summarize Previous Jobs - LLM",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Fail Job Summary Generation - Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Model (Fallback)": {
      "ai_languageModel": [
        [
          {
            "node": "Summarize Previous Jobs - LLM",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Summarize Previous Jobs - LLM": {
      "main": [
        [
          {
            "node": "If Summary Text Present - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Previous Jobs": {
      "main": [
        [
          {
            "node": "Summarize Previous Jobs - LLM",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "No Operation, do nothing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-08-25T15:00:43.080Z",
  "id": "5e0tIRVmOZY0LlMF",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "[2040] Sub > Linkedin > Summarize Previous Jobs and Create Connection Message",
  "nodes": [
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        1184,
        -48
      ],
      "id": "92f46e94-fcf5-4a2c-8c69-d5528e9b3250",
      "name": "Receive Person Inputs - Subflow Trigger",
      "notes": "PHASE: Input; Purpose: Receive person inputs for LinkedIn connection message generation in a subflow; Inputs: recId (Airtable People record ID) and linkedinLink from parent via passthrough; Outputs: Forwards the same payload unchanged to downstream nodes; Dependencies: Invoked as Execute Workflow Trigger by a parent workflow; Special Cases: linkedinLink must be a valid LinkedIn profile URL and recId must be present for later Airtable update."
    },
    {
      "parameters": {
        "model": "=google/gemini-2.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2768,
        -320
      ],
      "id": "cea1d504-ad77-4978-89d9-1dbeb5237089",
      "name": "Configure Chat Model - Util OpenRouter",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration; Purpose: Configure the primary OpenRouter chat model for downstream Chain LLM text generation; Inputs: None (static selection of google/gemini-2.5-flash); Outputs: Language model handle to be consumed by the Chain LLM; Dependencies: OpenRouter Boost Performance credential; Special Cases: Be mindful of rate limits and latency, a separate fallback model is connected for resilience."
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.apify.com/v2/acts/apimaestro~linkedin-profile-detail/run-sync-get-dataset-items",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').item.json.config.vault.APIFY_TOKENS }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"username\": $('Receive Person Inputs - Subflow Trigger').first().json.linkedinLink } }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2304,
        -288
      ],
      "id": "282bd00c-7f91-4d7b-a3bb-1c4822bee850",
      "name": "Get LinkedIn Profile Details - HTTP Apify",
      "alwaysOutputData": true,
      "retryOnFail": false,
      "onError": "continueErrorOutput",
      "notes": "PHASE: Execution; Purpose: Retrieve LinkedIn profile details using Apify actor synchronous dataset endpoint; Inputs: linkedinLink from Start mapped as { username } in JSON body; Outputs: Array of dataset items with fields like basic_info for downstream LLM; Dependencies: HTTP Query Auth (Apify Boost Connect) and Apify run-sync-get-dataset-items endpoint; Special Cases: Possible empty or partial responses and rate limits, alwaysOutputData=true so handle empty arrays."
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=LinkedIn content:\n{{ $json.toJsonString() }}",
        "needsFallback": true,
        "messages": {
          "messageValues": [
            {
              "message": "=Role\nYou are a smart, efficient writing assistant.\n\nAction\nGenerate a very short, punchy connection‚Äêrequest opener in {{ $('Workflow Data').first().json.config.variable.default_llm_output_language }} based on LinkedIn profile data.\n\nContext\nYou will receive a structured object (JSON or similar) containing a person‚Äôs LinkedIn fields (name, current title, past roles, interests, etc.). Your output will be used directly as the connection‚Äêrequest message.\n\nRequirements\n\nUse this exact template:\n\n‚ÄúHello name, I really enjoyed seeing thingAboutThem. I‚Äôm growing my business and professional network, and I thought it would be great to connect.‚Äù\n\nthingAboutThem must come from your own analysis of their LinkedIn profile (e.g. role transitions, specific achievements, industries, interests, skills, or causes) and not from copying text verbatim. Always rephrase.\n\nEnsure thingAboutThem creates a direct, natural link to their experience, expertise, or interests (e.g. ‚Äúyour move from finance to AI,‚Äù ‚Äúyour work in renewable energy,‚Äù ‚Äúyour leadership in scaling startups‚Äù).\n\nSound human and spontaneous, not automated.\n\nKeep it under 25 words.\n\nAvoid vague filler (‚Äúpassionate about‚Ä¶‚Äù)‚Äîbe ultra-concise and specific.\n\nOutput only the one‚Äêline English message, nothing else.\n"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.6,
      "position": [
        2752,
        -544
      ],
      "id": "75b984b9-c0e3-46af-883d-80a539faadd1",
      "name": "Generate Connection Message - Util OpenRouter",
      "retryOnFail": true,
      "notes": "PHASE: Execution; Purpose: Generate a concise French LinkedIn connection message from profile data using OpenRouter LLMs; Inputs: Profile JSON (e.g., basic_info) from Apify HTTP node and two connected chat models (primary and fallback); Outputs: $json.text containing a single one-line FR message per the template; Dependencies: OpenRouter Boost Performance credential via connected model nodes; Special Cases: Keep under 25 words, avoid verbatim copying, output only the line, empty output triggers retry and eventual error."
    },
    {
      "parameters": {
        "model": "=openai/gpt-4.1-mini",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2896,
        -320
      ],
      "id": "75856ad4-5887-476f-b773-e7640850cfa5",
      "name": "Configure Fallback Chat Model - Util OpenRouter",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration; Purpose: Configure fallback OpenRouter chat model for Chain LLM resilience; Inputs: None (static configuration); Outputs: Language model handle provided as secondary input to the Chain LLM; Dependencies: OpenRouter Boost Performance credential; Special Cases: Engages only when the primary model is unavailable or errors."
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "={{ JSON.stringify($json) }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        3552,
        -352
      ],
      "id": "6786ac68-c848-4b4c-a4a8-bf56f9c993fb",
      "name": "Fail Workflow - Error",
      "notes": "PHASE: Error Handling; Purpose: Fail the workflow when no valid connection message is produced after retries; Inputs: Current item JSON serialized into errorObject; Outputs: Throws an error and stops execution; Dependencies: None; Special Cases: Triggered from retry guard path only to avoid failing successful items."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "def6644c-7b30-4c64-97cb-70dce510f2a1",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "389e619d-3986-49ea-93dc-ecae24324c50",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3104,
        -592
      ],
      "id": "a6c881db-d243-4d17-89ce-21da2bfcb95a",
      "name": "If Connection Message Present - IF",
      "notes": "PHASE: Execution; Purpose: Route execution only if a valid message was generated; Inputs: $json.text from Chain LLM node; Outputs: True branch when text exists and is not empty, else False branch; Dependencies: True -> Airtable update, False -> retry guard; Special Cases: Protects against undefined and empty string outputs."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "06b508ed-51fa-4bc9-960c-f8f86b9d3273",
              "leftValue": "={{ $runIndex }}",
              "rightValue": 2,
              "operator": {
                "type": "number",
                "operation": "lt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3328,
        -352
      ],
      "id": "939c5516-bd5a-4eab-915b-433e27b20da9",
      "name": "If Attempts lt 2 - IF",
      "notes": "PHASE: Execution; Purpose: Allow a single retry of message generation based on run index; Inputs: $runIndex (0-based) from the runtime; Outputs: True when $runIndex < 2 to permit retry, False to stop with error; Dependencies: True -> Chain LLM, False -> Fail Workflow; Special Cases: Tune the numeric threshold to modify allowed retries."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "a135385d-9f4a-45d4-86f5-45e980f3b48e",
              "leftValue": "={{ $json.basic_info }}",
              "rightValue": "",
              "operator": {
                "type": "object",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "d8f99cae-aae3-444d-aed6-463758404f39",
              "leftValue": "={{ $json.basic_info }}",
              "rightValue": "",
              "operator": {
                "type": "object",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2528,
        -288
      ],
      "id": "7cfe683f-df26-4fa3-9cf2-b01ed2a278ad",
      "name": "If Profile Data Present - IF",
      "notes": "PHASE: Execution; Purpose: Ensure required profile data exists before prompting the LLM; Inputs: $json.basic_info from the Apify fetch; Outputs: True if object exists and is non-empty, False otherwise; Dependencies: True -> LLM generation, False -> No Operation; Special Cases: Guards against empty API responses and schema changes."
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        2816,
        -144
      ],
      "id": "8e3ebbab-4468-4076-9b87-3da42673ddc8",
      "name": "No Operation - Util",
      "notes": "PHASE: Utility; Purpose: Provide a clear no-op endpoint for the false branch when profile data is missing; Inputs: Item from IF false path; Outputs: Unmodified item or termination of branch; Dependencies: None; Special Cases: Serves documentation purposes only and can be removed without side effects."
    },
    {
      "parameters": {
        "content": "# LinkedIn Connection Message ‚Äì Subflow\n\n1. This subworkflow generates a concise French LinkedIn connection message for a person and writes it back to Airtable.\n\n2. It receives **recId** and **linkedinLink** from a parent workflow, fetches profile details via **Apify**, and validates that required data is present.\n\n3. The workflow provisions **primary and fallback OpenRouter LLMs** to compose a single-line French opener under 25 words **without verbatim copying**.\n\n4. An **IF check ensures** a valid message is produced; a **guarded retry** allows one reattempt before failing the run.\n\n5. On success, the message is written to **People** in Airtable; otherwise, the flow terminates with no update.\n\n---\n\n### üîó Key Integrations\n- **Apify API**  \n- **OpenRouter** (LLMs with fallback)  \n- **Airtable API**\n",
        "height": 624,
        "width": 672
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        112
      ],
      "id": "2ecb33a2-dc4c-4ebd-b529-bc757a361f83",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "url": "=https://api.apify.com/v2/users/me/limits",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').item.json.config.vault.APIFY_TOKENS }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1856,
        -128
      ],
      "id": "6e089dc6-f679-49fd-ba48-1c404610b22c",
      "name": "Apify - Get limits",
      "retryOnFail": true,
      "notes": "PHASE: Execution | Purpose: Start an Apify task run for the created task. | Inputs: task_id and Apify Bearer auth. | Outputs: Run metadata including run ID and status. | Dependencies: Apify API v2 /actor-tasks/{taskId}/runs. | Special Cases: Asynchronous start; handle pending states, retries, and timeouts."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "2f4064fa-089d-4c2e-91e8-f5d206f5e92c",
              "leftValue": "={{ $json.data.limits.maxConcurrentActorJobs }}",
              "rightValue": "={{ $json.data.current.activeActorJobCount }}",
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            },
            {
              "id": "18405df6-a422-4129-8fd0-818ecb853b18",
              "leftValue": "={{ $json.data.limits.maxActorMemoryGbytes }}",
              "rightValue": "={{ Math.ceil($json.data.current.actorMemoryGbytes + ($('Apify Actors Config - Set').item.json.options.memoryMbytes / 1000)) }}",
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2080,
        -128
      ],
      "id": "4ba4a9cd-6d76-4c08-a318-597c9f7856cd",
      "name": "Check Apify Capacity - IF"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b132536b-98f5-4aa6-83f1-de045241ff94",
              "name": "options.memoryMbytes",
              "value": 128,
              "type": "number"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1632,
        -48
      ],
      "id": "7190eab5-42b1-40f2-b20d-251cd60f5934",
      "name": "Apify Actors Config - Set"
    },
    {
      "parameters": {
        "amount": "={{ Math.floor(Math.random() * (35 - 5 + 1)) + 5 }}"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        2816,
        224
      ],
      "id": "731b8255-6601-4f0d-a8f5-14468ef2c4f7",
      "name": "Wait",
      "webhookId": "555772e3-7ef8-4758-a09a-e4ea74fea801"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "52ecb72f-3a3e-429a-9a1c-def4089c2afc",
              "leftValue": "={{ $json.error.status }}",
              "rightValue": 402,
              "operator": {
                "type": "number",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2528,
        -16
      ],
      "id": "76d1b6ab-2eec-44c1-a9fb-0fc4ac7f109d",
      "name": "Apify Error 402 - IF"
    },
    {
      "parameters": {
        "errorMessage": "={{ $json.error }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        2832,
        416
      ],
      "id": "e584b618-bfb6-4338-8ff7-2c981b96798a",
      "name": "Stop and Error"
    },
    {
      "parameters": {
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1408,
        -48
      ],
      "id": "4a54d00e-895f-4617-a3af-9f4c0b0cc07c",
      "name": "Workflow Data"
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.airtable.com/v0/{{ $('Workflow Data').first().json.config.vault.BASE_ID }}/People/{{ $('Workflow Data').first().json.recId }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').first().json.config.vault.AIRTABLE_PERSONAL_ACCESS_TOKEN }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ \n  JSON.stringify({\n    fields: {\n      connectionLinkedinMessage: $json.text\n    }\n  })\n}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3328,
        -640
      ],
      "id": "f05a2a09-63ab-44ad-b212-0854fbf84c21",
      "name": "Update People Connection Message - AT People",
      "retryOnFail": true
    },
    {
      "parameters": {
        "model": "=google/gemini-2.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2768,
        -912
      ],
      "id": "f68d13f2-c8e8-44a3-bc2c-28991b67632d",
      "name": "Chat Model - OpenRouter",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration Purpose: Provide the OpenRouter Gemini 2.5 Flash chat model handle for the summarization chain. Inputs: OpenRouter API credentials only, no item data consumed. Outputs: Language model instance passed to the LLM chain. Dependencies: OpenRouter Boost Performance credentials and LangChain LLM nodes. Special Cases: Subject to OpenRouter rate limits/quotas; change model here to alter behavior."
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "={{ JSON.stringify($json) }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        3552,
        -864
      ],
      "id": "8904cfd3-c866-4899-8993-39645efea472",
      "name": "Fail Job Summary Generation - Error Handler",
      "notes": "PHASE: Error Handling Purpose: Fail the run when job summary generation has exceeded retries or produced invalid/empty output. Inputs: Current item ($json) and $runIndex for context. Outputs: Throws an error object to halt execution. Dependencies: Built-in error handling only. Special Cases: Serializes the current item into errorObject; used on the false branch of retry guard."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "def6644c-7b30-4c64-97cb-70dce510f2a1",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "389e619d-3986-49ea-93dc-ecae24324c50",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3104,
        -1104
      ],
      "id": "4db1421e-378e-4278-9615-a36e75d3b11c",
      "name": "If Summary Text Present - IF",
      "notes": "PHASE: Execution Purpose: Guard that the LLM output contains a non-empty text summary before updating Airtable. Inputs: Item from LLM chain containing potential 'text' property. Outputs: True branch when $json.text exists and notEmpty; false branch when missing or empty. Dependencies: LLM chain output shape. Special Cases: Strict type validation and caseSensitive checks enabled."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "06b508ed-51fa-4bc9-960c-f8f86b9d3273",
              "leftValue": "={{ $runIndex }}",
              "rightValue": 2,
              "operator": {
                "type": "number",
                "operation": "lt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3328,
        -864
      ],
      "id": "bb25f00c-9362-424b-9f49-be6f4d050767",
      "name": "If Retry Count LT 2 - IF",
      "notes": "PHASE: Execution Purpose: Gate retries so the LLM is called again only when $runIndex is less than 2; otherwise route to failure. Inputs: Implicit $runIndex. Outputs: True branch to LLM retry; false branch to error handler. Dependencies: LLM chain node and Stop/Error node. Special Cases: Adjust threshold to change retry policy."
    },
    {
      "parameters": {
        "model": "=openai/gpt-4.1-mini",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2896,
        -912
      ],
      "id": "e4dd29fd-12cf-49c9-94e7-2aa8e59a5301",
      "name": "Chat Model (Fallback)",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration Purpose: Provide a fallback OpenRouter chat model used by the LLM chain if the primary model fails. Inputs: OpenRouter API credentials. Outputs: Fallback model handle to the chain. Dependencies: OpenRouter Boost Performance credentials; LangChain LLM nodes. Special Cases: Select a concrete model here to guarantee deterministic behavior."
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=###Fullname of the person :\n{{ $json.basic_info.fullname }}\n\n###Job Title :\n{{ $json.basic_info.headline }}\n\n###Company :\n{{ $json.basic_info.current_company }}\n\n###Previous Jobs :\n```json\n{{ $json.experience.toJsonString() }}\n",
        "needsFallback": true,
        "messages": {
          "messageValues": [
            {
              "message": "=**Role:**\nYou are an intelligent assistant specialized in creating professional narrative summaries from raw data, with the goal of enriching a CRM and better understanding a person‚Äôs profile.\n\n**Action:**\nAnalyze raw JSON work-history data and produce a smooth, natural one-paragraph summary.\n\n**Context:**\nThe JSON contains a person‚Äôs employment history in reverse-chronological order, including job titles, organizations, dates, and responsibilities or achievements.\n\n**Requirements:**\n\n* For each position (most recent first), include:\n\n  1. Job title\n  2. Organization (if provided)\n  3. Start and end dates (or ‚ÄúPresent‚Äù if ongoing)\n  4. Key responsibilities or achievements (if provided)\n* Write in concise, polished **{{ $('Workflow Data').first().json.config.variable.default_llm_output_language }}** language, in no more than one paragraph.\n* Use a tone that conveys the person‚Äôs career trajectory, areas of expertise, and level of experience.\n* Conclude with a brief sentence summarizing the progression or breadth of experience, useful for CRM qualification.\n* Do not invent missing details; use neutral phrasing instead.\n"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        2752,
        -1136
      ],
      "id": "cf316cb6-5e1d-4238-9a1e-a8fcff957c01",
      "name": "Summarize Previous Jobs - LLM",
      "retryOnFail": true,
      "notes": "PHASE: Execution Purpose: Use the LLM to produce a one-paragraph professional summary of prior roles for CRM enrichment. Inputs: fullName, jobTitle, companyName (string), previousJobs (JSON string), and $vars.default_llm_output_language. Outputs: text field with the summary. Dependencies: OpenRouter model nodes and LangChain chain. Special Cases: Avoid indexing companyName; ensure previousJobs is valid JSON; fallback requires a second model input."
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.airtable.com/v0/{{ $('Workflow Data').first().json.config.vault.BASE_ID }}/People/{{ $('Workflow Data').first().json.recId }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').first().json.config.vault.AIRTABLE_PERSONAL_ACCESS_TOKEN }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"fields\": {\n    \"previousJobSummary\": {{ JSON.stringify($json.text) }}\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3328,
        -1152
      ],
      "id": "612933fd-f2c8-4741-9e51-e14c49dad7df",
      "name": "Update Previous Job Summary - AT People",
      "retryOnFail": true
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "c8946e59-ee43-4b49-8056-7180dd42d7c1",
              "leftValue": "={{ $json.experience }}",
              "rightValue": "",
              "operator": {
                "type": "array",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "ca221d44-e258-4167-a011-fb1be218a97a",
              "leftValue": "={{ $json.experience[0] }}",
              "rightValue": "",
              "operator": {
                "type": "object",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2528,
        -880
      ],
      "id": "9c0a60ba-42d7-42e0-abab-995650dfa2d6",
      "name": "Check Previous Jobs"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        2816,
        -736
      ],
      "id": "388a3efc-af82-4645-920f-c9c82c06f214",
      "name": "No Operation, do nothing"
    }
  ],
  "repo_name": "boost-prospect-v2",
  "repo_owner": "ultimvision",
  "repo_path": "workflows",
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "xqIMv4nOqM7qzjDi"
  },
  "shared": [
    {
      "createdAt": "2025-08-25T15:00:43.080Z",
      "updatedAt": "2025-08-25T15:00:43.080Z",
      "role": "workflow:owner",
      "workflowId": "5e0tIRVmOZY0LlMF",
      "projectId": "zxVtQj8AiJx7hlkL"
    }
  ],
  "staticData": null,
  "tags": [
    {
      "createdAt": "2025-09-07T13:56:33.651Z",
      "updatedAt": "2025-09-07T13:56:33.651Z",
      "id": "p3ITgML19KuPj74r",
      "name": "Version : 1.1"
    },
    {
      "createdAt": "2025-09-05T11:43:12.743Z",
      "updatedAt": "2025-09-05T11:43:12.743Z",
      "id": "2WGDY3428pMfpzn6",
      "name": "Boost Prospect"
    }
  ],
  "triggerCount": 0,
  "updatedAt": "2025-09-07T14:15:10.950Z",
  "versionId": "d44990f4-cf71-4b93-a7af-10179c362c5e"
}