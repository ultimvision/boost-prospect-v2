{
  "active": false,
  "connections": {
    "Get Profile Posts - Apify LinkedIn": {
      "main": [
        [
          {
            "node": "Aggregate Items - Util",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Apify Error 402 - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Items - Util": {
      "main": [
        [
          {
            "node": "If Data Exists - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Post Behavior Summary - LLM LinkedIn": {
      "main": [
        [
          {
            "node": "If Post Report Exists - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Model - OpenRouter Fallback": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Post Behavior Summary - LLM LinkedIn",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Chat Model - OpenRouter": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Post Behavior Summary - LLM LinkedIn",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "If Post Report Exists - IF": {
      "main": [
        [
          {
            "node": "Update People Post Behavior - AT People",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Retry Count LT 2 - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Retry Count LT 2 - IF": {
      "main": [
        [
          {
            "node": "Generate Post Behavior Summary - LLM LinkedIn",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Fail Run - Error Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Receive Inputs - Subflow Trigger": {
      "main": [
        [
          {
            "node": "Workflow Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Data Exists - IF": {
      "main": [
        [
          {
            "node": "Generate Post Behavior Summary - LLM LinkedIn",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Update People Post Behavior - AT People1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Apify Actors Config - Set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify Error 402 - IF": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Stop and Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify - Get limits": {
      "main": [
        [
          {
            "node": "Check Apify Capacity - IF",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Apify Capacity - IF": {
      "main": [
        [
          {
            "node": "Get Profile Posts - Apify LinkedIn",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apify Actors Config - Set": {
      "main": [
        [
          {
            "node": "Apify - Get limits",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Workflow Data": {
      "main": [
        [
          {
            "node": "Apify Actors Config - Set",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-08-25T15:08:49.060Z",
  "id": "LSbKGWcNI262tDWI",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "Processing > Sub > Linkedin Profile Posts > Apify [2200]",
  "nodes": [
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.apify.com/v2/acts/apimaestro~linkedin-profile-posts/run-sync-get-dataset-items",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').item.json.config.vault.APIFY_TOKENS }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \n      \"username\": $('Receive Inputs - Subflow Trigger').item.json.linkedinLink,\n      \"limit\" : 10,\n      \"page_number\": 1 \n} }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3376,
        268
      ],
      "id": "d896dea5-fdc1-4de9-82c2-8dec119acd48",
      "name": "Get Profile Posts - Apify LinkedIn",
      "alwaysOutputData": true,
      "retryOnFail": false,
      "onError": "continueErrorOutput",
      "notes": "PHASE: Execution | Purpose: Run Apify actor to fetch recent LinkedIn profile posts for a given username/link. | Inputs: linkedinLink from Start; HTTP query auth via credential 'Apify Boost Connect'; JSON body includes username, limit=10, page_number=1. | Outputs: JSON array of dataset items (typically under data[]), each representing a post. | Dependencies: Apify API act apimaestro~linkedin-profile-posts; HTTP Request node with Accept: application/json. | Special Cases: Actor must handle full LinkedIn profile URLs vs usernames; may return empty data on invalid input; subject to Apify rate limits and 4xx/5xx; consider retries or fallback."
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        3600,
        172
      ],
      "id": "7a5fac8e-b6e4-4f25-aa5a-c8916511cd75",
      "name": "Aggregate Items - Util",
      "notes": "PHASE: Utility | Purpose: Aggregate all incoming post items into a single item payload for easier branching and analysis. | Inputs: Array of items from Apify HTTP response. | Outputs: One item with a data[] array containing all aggregated items (aggregateAllItemData). | Dependencies: Built-in Aggregate node. | Special Cases: If input is empty, data[] is empty; downstream conditions must guard against empties."
    },
    {
      "parameters": {
        "errorType": "errorObject",
        "errorObject": "={{ JSON.stringify($json) }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        4848,
        120
      ],
      "id": "7d714d28-3245-4607-8e61-c77561a629e7",
      "name": "Fail Run - Error Handler",
      "notes": "PHASE: Error Handling | Purpose: Stop execution and raise an error with the current item as context. | Inputs: Current $json serialized via errorObject. | Outputs: Workflow termination with error. | Dependencies: None. | Special Cases: Triggered when retry threshold is reached or analysis produced no usable output; ensure upstream monitors failures."
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=**Raw input data (JSON):**\n{{ JSON.stringify($json.data) }}",
        "needsFallback": true,
        "messages": {
          "messageValues": [
            {
              "message": "=**Role:**\nYou are an AI-powered expert in behavioral analysis, specialized in creating concise professional summaries from structured posting data to enrich a CRM and better understand a person’s communication style and objectives.\n\n**Action:**\nAnalyze structured data describing a user’s professional network posts (LinkedIn, internal forums, etc.) and produce a single, fluent paragraph in **{{ $('Workflow Data').first().json.config.variable.default_llm_output_language }}** language summarizing their posting habits, thematic focus, style, performance, and inferred objectives.\n\n**Context:**\nThe data includes content, topics, formats, timestamps, and engagement metrics, possibly over multiple periods.\n\n**Requirements:**\n\n* In **one paragraph only**, synthesize key insights covering:\n\n  1. Posting frequency and regularity\n  2. Main topics and depth of coverage\n  3. Preferred formats and tone\n  4. Average engagement and notable highs/lows\n  5. Typical publishing days/times and any cadence shifts\n  6. Likely objectives (e.g., sharing expertise, networking, visibility) and notable changes over time\n* If multiple datasets exist, aggregate statistics and note major evolutions in strategy.\n* Maintain a **concise, polished, and neutral** tone suitable for CRM enrichment and user profiling.\n* Do not invent missing information; use cautious, neutral phrasing instead.\n"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4048,
        -80
      ],
      "id": "54aa37d0-0147-4663-a12f-90481f382da7",
      "name": "Generate Post Behavior Summary - LLM LinkedIn",
      "retryOnFail": true,
      "notes": "PHASE: Execution | Purpose: Generate a concise one-paragraph summary of LinkedIn posting behavior from structured post data using an LLM chain. | Inputs: ai_languageModel from OpenRouter; posts under $json.data; $vars.default_llm_output_language. | Outputs: Single item with text field containing the summary. | Dependencies: n8n LangChain LLM Chain; OpenRouter credential and models. | Special Cases: If data[] is empty, downstream IF routes to no-op; needsFallback=true supports fallback model; adhere to prompt constraints to avoid invented details."
    },
    {
      "parameters": {
        "model": "=openai/gpt-4.1-mini",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        4184,
        144
      ],
      "id": "c1d02711-7f86-4d7b-91d5-175c943574a9",
      "name": "Chat Model - OpenRouter Fallback",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration | Purpose: Provide the fallback OpenRouter chat model to the analysis chain. | Inputs: OpenRouter credential 'OpenRouter Boost Performance'; model configured in node. | Outputs: ai_languageModel handle for the chain. | Dependencies: OpenRouter API via n8n LangChain node. | Special Cases: Activated under primary model failure or rate limit; ensure prompt and temperature parity if consistency is required."
    },
    {
      "parameters": {
        "model": "=google/gemini-2.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        4056,
        144
      ],
      "id": "4735c9de-b56a-4ff3-8ab7-a0a371787d27",
      "name": "Chat Model - OpenRouter",
      "credentials": {
        "openRouterApi": {
          "id": "0qavXgV1FZOxQIaU",
          "name": "OpenRouter"
        }
      },
      "notes": "PHASE: Configuration | Purpose: Provide the primary OpenRouter chat model to the analysis chain. | Inputs: OpenRouter credential 'OpenRouter Boost Performance'; model google/gemini-2.5-flash. | Outputs: ai_languageModel handle consumable by the LLM chain. | Dependencies: OpenRouter API via n8n LangChain node. | Special Cases: Rate limits and outages may require using the fallback model; keep model id consistent across environments."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "def6644c-7b30-4c64-97cb-70dce510f2a1",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "389e619d-3986-49ea-93dc-ecae24324c50",
              "leftValue": "={{ $json.text }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        4400,
        -48
      ],
      "id": "8ca77a7d-e8b2-4ff2-9580-bb1c6cf05c85",
      "name": "If Post Report Exists - IF",
      "notes": "PHASE: Execution | Purpose: Check if the LLM produced a non-empty summary (text). | Inputs: $json.text from the analysis node. | Outputs: True path if text exists and not empty; false path otherwise. | Dependencies: True -> update Airtable; False -> retry logic. | Special Cases: Verify the false output is connected to the retry decision; prevent empty writes to Airtable."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "06b508ed-51fa-4bc9-960c-f8f86b9d3273",
              "leftValue": "={{ $runIndex }}",
              "rightValue": 2,
              "operator": {
                "type": "number",
                "operation": "lt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        4624,
        120
      ],
      "id": "17b47d08-ae69-40eb-a6f2-52f7ccd607ff",
      "name": "If Retry Count LT 2 - IF",
      "notes": "PHASE: Error Handling | Purpose: Permit at most one retry of the analysis when the first attempt produced no summary. | Inputs: $runIndex compared to 2 (lt). | Outputs: True when $runIndex < 2, else False. | Dependencies: True -> re-run analysis; False -> fail via error handler. | Special Cases: The previous label implied <1 but logic is <2; update naming if policy changes; consider exponential backoff if adding more retries."
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        2256,
        412
      ],
      "id": "a66f4d3b-574d-4bc9-8453-90065c882bd7",
      "name": "Receive Inputs - Subflow Trigger",
      "notes": "PHASE: Input | Purpose: Receive and pass through parent workflow inputs for this subflow. | Inputs: recId and linkedinLink from the caller or pinned data. | Outputs: Same item forwarded to the next node. | Dependencies: Execute Workflow Trigger; parent workflow contract. | Special Cases: Validate presence of required fields upstream to prevent runtime errors."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "b76c2c04-83d3-4893-bfa8-e0e0ef7118a1",
              "leftValue": "={{ $json.data }}",
              "rightValue": "",
              "operator": {
                "type": "array",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "16a8f076-1bef-4398-9d4a-bd3639a4bd90",
              "leftValue": "={{ $json.data }}",
              "rightValue": "",
              "operator": {
                "type": "array",
                "operation": "notEmpty",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3824,
        172
      ],
      "id": "312109d4-9b23-4344-b4c9-f55da47d756a",
      "name": "If Data Exists - IF",
      "notes": "PHASE: Execution | Purpose: Check if aggregated data[] has items before invoking the analysis. | Inputs: $json.data from Aggregate. | Outputs: True path if data exists and is not empty; False path otherwise. | Dependencies: True -> analysis chain; False -> No Operation. | Special Cases: Prevents unnecessary LLM calls on empty datasets; ensure aggregation produced data[]."
    },
    {
      "parameters": {
        "content": "# LinkedIn Post Behavior Analysis – Subflow\n\n1. This subflow collects a LinkedIn profile's recent posts, analyzes posting behavior with an LLM, and updates the person's record in Airtable. \n\n2. It receives **recId** and **linkedinLink**, fetches up to **10 posts via an Apify actor**, aggregates results, and gates execution on data presence. \n\n3. The workflow provisions **primary and fallback OpenRouter chat models** and runs an **LLM chain** to generate a concise summary paragraph. \n\n4. An **IF check validates** a non-empty summary; a **retry gate** allows one reattempt before failing the run. \n\n5. On success, the summary is written to **People.postBehavior** in Airtable; when no posts exist, the flow ends in a **no-op sink**. \n\n---\n\n### 🔗 Key Integrations\n- **Apify API**  \n- **OpenRouter** (via *n8n LangChain*)  \n- **Airtable API**\n",
        "height": 544,
        "width": 1040
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1088,
        176
      ],
      "id": "5f5e2fdf-0c3b-491d-9975-50f1fae932d0",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "amount": "={{ Math.floor(Math.random() * (35 - 5 + 1)) + 5 }}"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        3824,
        508
      ],
      "id": "0e6201f3-e343-4412-a4e6-47f2dd9bc821",
      "name": "Wait",
      "webhookId": "555772e3-7ef8-4758-a09a-e4ea74fea801"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "52ecb72f-3a3e-429a-9a1c-def4089c2afc",
              "leftValue": "={{ $json.error.status }}",
              "rightValue": 402,
              "operator": {
                "type": "number",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3600,
        412
      ],
      "id": "a5986869-c4d5-4e83-9684-663bb97e3970",
      "name": "Apify Error 402 - IF"
    },
    {
      "parameters": {
        "errorMessage": "={{ $json.error.message }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        3824,
        700
      ],
      "id": "08abe4ad-e085-4798-be02-3c9bbbd49bf3",
      "name": "Stop and Error"
    },
    {
      "parameters": {
        "url": "=https://api.apify.com/v2/users/me/limits",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').item.json.config.vault.APIFY_TOKENS }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2928,
        340
      ],
      "id": "947caf4f-059a-4acd-9b77-0d4b147e1cd8",
      "name": "Apify - Get limits",
      "retryOnFail": true,
      "notes": "PHASE: Execution | Purpose: Start an Apify task run for the created task. | Inputs: task_id and Apify Bearer auth. | Outputs: Run metadata including run ID and status. | Dependencies: Apify API v2 /actor-tasks/{taskId}/runs. | Special Cases: Asynchronous start; handle pending states, retries, and timeouts."
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "2f4064fa-089d-4c2e-91e8-f5d206f5e92c",
              "leftValue": "={{ $json.data.limits.maxConcurrentActorJobs }}",
              "rightValue": "={{ $json.data.current.activeActorJobCount }}",
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            },
            {
              "id": "18405df6-a422-4129-8fd0-818ecb853b18",
              "leftValue": "={{ $json.data.limits.maxActorMemoryGbytes }}",
              "rightValue": "={{ Math.ceil($json.data.current.actorMemoryGbytes + ($('Apify Actors Config - Set').item.json.options.memoryMbytes / 1000)) }}",
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3152,
        340
      ],
      "id": "f4ea7b19-13ea-4645-984b-44d5010698a1",
      "name": "Check Apify Capacity - IF"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b132536b-98f5-4aa6-83f1-de045241ff94",
              "name": "options.memoryMbytes",
              "value": 128,
              "type": "number"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2704,
        412
      ],
      "id": "cffac654-ff50-4f8b-b46c-1ade0cfe39a8",
      "name": "Apify Actors Config - Set"
    },
    {
      "parameters": {
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2480,
        412
      ],
      "id": "bb6a023d-e0cb-4338-bdf2-5de378b742ba",
      "name": "Workflow Data"
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.airtable.com/v0/{{ $('Workflow Data').first().json.config.vault.BASE_ID }}/People/{{ $('Workflow Data').first().json.recId }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').first().json.config.vault.AIRTABLE_PERSONAL_ACCESS_TOKEN }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ \n  JSON.stringify({\n    fields: {\n      postBehavior: $json.text,\n      jsonProfileLinkedInPosts: JSON.stringify($('Aggregate Items - Util').first().json.data),\n      profileLinkedInPostsProcessed: true\n    }\n  })\n}}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4624,
        -96
      ],
      "id": "a2777238-904f-460b-a6a8-bf3fead3f04a",
      "name": "Update People Post Behavior - AT People",
      "retryOnFail": true
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.airtable.com/v0/{{ $('Workflow Data').first().json.config.vault.BASE_ID }}/People/{{ $('Workflow Data').first().json.recId }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $('Workflow Data').first().json.config.vault.AIRTABLE_PERSONAL_ACCESS_TOKEN }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ \n  JSON.stringify({\n    fields: {\n      profileLinkedInPostsProcessed: true\n    }\n  })\n}}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4112,
        320
      ],
      "id": "6461b7e5-c2be-46da-92e3-b406b1b0f5bd",
      "name": "Update People Post Behavior - AT People1",
      "retryOnFail": true
    }
  ],
  "repo_name": "boost-prospect-v2",
  "repo_owner": "ultimvision",
  "repo_path": "workflows",
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "xqIMv4nOqM7qzjDi"
  },
  "shared": [
    {
      "createdAt": "2025-08-25T15:08:49.060Z",
      "updatedAt": "2025-08-25T15:08:49.060Z",
      "role": "workflow:owner",
      "workflowId": "LSbKGWcNI262tDWI",
      "projectId": "zxVtQj8AiJx7hlkL"
    }
  ],
  "staticData": null,
  "tags": [
    {
      "createdAt": "2025-09-01T18:44:12.239Z",
      "updatedAt": "2025-09-01T18:44:12.239Z",
      "id": "DxA0rKpUpLnrWgla",
      "name": "Router"
    },
    {
      "createdAt": "2025-08-26T10:41:15.177Z",
      "updatedAt": "2025-08-26T10:41:15.177Z",
      "id": "SkbNGlFjPGusXj0B",
      "name": "LinkedIn"
    },
    {
      "createdAt": "2025-08-26T10:33:17.006Z",
      "updatedAt": "2025-08-26T10:33:17.006Z",
      "id": "Emw8imBHM3k6zkUo",
      "name": "Sub-Workflow"
    },
    {
      "createdAt": "2025-08-25T15:32:46.509Z",
      "updatedAt": "2025-08-25T15:32:46.509Z",
      "id": "4ptvvLb7NgD8g7Ar",
      "name": "Apify"
    }
  ],
  "triggerCount": 0,
  "updatedAt": "2025-09-04T11:57:05.590Z",
  "versionId": "51efebf3-404a-4493-be10-e54a4942a165"
}